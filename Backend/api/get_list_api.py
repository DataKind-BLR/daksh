import argparse
import datetime
import logging
import urllib
import urlparse
import pandas as pd
from requests import Session
from settings import SETTINGS
from time import sleep
from glob import glob
import os


logging.basicConfig(filename='wrapper.log',level=logging.DEBUG)

class DataAPIWrapper(object):
    """
    A Wrapper for zynata data api
    """

    def __init__(self):
        self.session = Session()
        self.session.headers.update({"Connection":"close"})


    def login(self, **login_params):
        """
        Logins with the given credentials

        Params
        ------

        - login_params = Takes a hash map containing keys username and password
        example:
                {"username":"name", "password":"xyz"}
        """
        if "username" not in login_params or "password" not in login_params:
            raise Exception("Please Provide username and password")
        url = "http://zynata.com/login?portal=dakshlegal.in"
        data = {"email": login_params["username"], "password": login_params["password"],
                "portal":"dakshlegal.in"}
        resp = self.session.post(url, data=data)
        if resp.status_code == 200:
            logging.info("Login Successful")
            return resp.cookies.get_dict()
        else:
            raise Exception("Invalid Username or Password")


    def execute(self, cols, filterby, n="nil"):
        """
        Form the url from the given columns and filterby and execute the query

        Params
        ------

        - cols = a string containing all the column names
            example:
                "guid,combined_case_number...."

        - filterby = conditions by which the data has to be filtered
            example:
                "year='2014'"
        - n = number of rows. It is currently set to max of what the list API
              supports.

        Returns
        -------

        The data in a dataframe format.
        """
        url = "http://zynata.com/list/{0}?".format(SETTINGS["table"])
        params = {"cols":cols, "page":n, "cond":filterby}
        data = []
        offset_page = 1
        tmp_file = open("tmp.csv", "a")
        while True:
            sleep(10)
            print offset_page
            logging.info("Getting Page {0}".format(offset_page))
            # params["offs"] = offset_page
            query = urllib.urlencode(params)
            query = urlparse.urljoin("", query)
            request_url = url + query
            # just incase some random error comes
            try:
                raw_resp = self.session.get(request_url)
                resp = raw_resp.json()
                if 'error' in resp.keys():
                    raise Exception("Failed to load resource. {0}".format(resp["error"]))
                elif 'data' in resp.keys():
                    if len(resp["data"]) > 0:
                        data.extend(resp['data'])
                        header = True if offset_page == 1 else False
                        pd.DataFrame(resp['data']).to_csv(tmp_file,
                                                          header=header,
                                                          index=False)
                        offset_page += 1
                    else:
                        return pd.DataFrame(data)
                else:
                    raise Exception("Something Went Wrong")
            except:
                print self.session.get(request_url).text
                # if any error occurs during half way save the data.
                if len(data) > 0:
                    return pd.DataFrame(data)
                logging.warning("Failed for url {0}".format(request_url))
                logging.info(raw_resp.text)


    def get_data(self, args):
        """
        Get the data from the zynata API.

        Params
        ------

        - args = A dictionary containing all query and credential params
            example:
                {
                 "username": "xyz@abc.com",
                 "password": "pass",
                 "cols": ["a","b"...],
                 "filterby": ["a is not null", "year='2011'"],
                 "n": 10
                 }

        Returns
        -------
        The data frame and also writes the data to a csv format.
        The name of the file is generated by hashing the combination of
        cols and filterby
        """
        self.login(**args)
        cols = ", ".join(SETTINGS["cols"])
        filterby = " and ".join(SETTINGS["filterby"])
        data = self.execute(cols, filterby)
        logging.info("Number of rows fetched: {0}".format(len(data.index)))
        filename = "{0}.csv".format(hash("{0}{1}".format(cols, filterby)))
        logging.info("Writing to file {0}".format(filename))
        data.to_csv(filename, index=False)
        return data


if __name__ == "__main__":
    desc = "Pull Data from zynata list API day wise for the given time period"
    desc += "Set the columns and filter in the config file."
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument('username',
                        help='Username for the zynata platform')
    parser.add_argument('password',
                        help='Secret password')

    api = DataAPIWrapper()
    api.get_data(vars(parser.parse_args()))